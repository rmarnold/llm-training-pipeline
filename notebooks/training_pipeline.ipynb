{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# LLM Training Pipeline\n\nThis notebook provides an interactive interface for training a 7B parameter language model through the complete pipeline:\n\n1. **Data Preparation** - Download, clean, and tokenize training data\n2. **Pretraining** - Train on large text corpora with curriculum learning\n3. **SFT** - Supervised fine-tuning on instruction-response pairs\n4. **DPO** - Direct preference optimization for alignment\n5. **LoRA** - Optional domain-specific fine-tuning\n\n## Requirements\n\n- **GPU**: NVIDIA A100 80GB recommended, H100 for FP8 support\n- **Colab**: Pro/Pro+ recommended for longer training sessions\n- **Storage**: Google Drive for persistent checkpoints (recommended)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Step 0: Environment Setup\n\nRun these cells first to set up the training environment. Choose your deployment method below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ### 0.1 Detect Environment & Mount Google Drive\n#@markdown Run this cell to detect if running in Colab and mount Google Drive for persistent storage.\n\nimport os\nimport sys\n\n# Detect if running in Google Colab\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    print(\"Running in Google Colab\")\n    \n    # Mount Google Drive for persistent storage\n    from google.colab import drive\n    drive.mount('/content/drive')\n    \n    # Set up persistent directories on Google Drive\n    DRIVE_BASE = \"/content/drive/MyDrive/llm-training-pipeline\"\n    os.makedirs(DRIVE_BASE, exist_ok=True)\n    os.makedirs(f\"{DRIVE_BASE}/checkpoints\", exist_ok=True)\n    os.makedirs(f\"{DRIVE_BASE}/data\", exist_ok=True)\n    \n    print(f\"Google Drive mounted. Persistent storage at: {DRIVE_BASE}\")\nelse:\n    print(\"Running locally (not in Colab)\")\n    DRIVE_BASE = None"
  },
  {
   "cell_type": "code",
   "source": "#@title ### 0.2 Clone Repository & Install Dependencies\n#@markdown Choose your repository source and install dependencies.\n\n#@markdown ---\n#@markdown **Repository Settings:**\nREPO_URL = \"https://github.com/rmarnold/llm-training-pipeline.git\"  #@param {type:\"string\"}\nBRANCH = \"main\"  #@param {type:\"string\"}\n\nimport os\nimport subprocess\n\n# Clone or update repository\nREPO_DIR = \"/content/llm-training-pipeline\"\n\nif IN_COLAB:\n    if os.path.exists(REPO_DIR):\n        print(f\"Repository exists. Pulling latest changes...\")\n        %cd {REPO_DIR}\n        !git pull origin {BRANCH}\n    else:\n        print(f\"Cloning repository from {REPO_URL}...\")\n        !git clone -b {BRANCH} {REPO_URL} {REPO_DIR}\n        %cd {REPO_DIR}\n    \n    # Install core dependencies\n    print(\"\\n\" + \"=\"*50)\n    print(\"Installing dependencies...\")\n    print(\"=\"*50)\n    \n    # Install the package with colab extras (includes pyfastcopy, ipywidgets)\n    !pip install -q -e \".[colab]\"\n    \n    # Verify colab extras installed\n    colab_extras_ok = True\n    try:\n        import pyfastcopy\n        print(\"✓ pyfastcopy installed (faster file copying)\")\n    except ImportError:\n        print(\"⚠ pyfastcopy not available\")\n        colab_extras_ok = False\n    \n    try:\n        import ipywidgets\n        print(\"✓ ipywidgets installed (better progress bars)\")\n    except ImportError:\n        print(\"⚠ ipywidgets not available\")\n        colab_extras_ok = False\n    \n    # Install flash-attn separately (requires special handling)\n    print(\"\\nInstalling flash-attention (this may take a few minutes)...\")\n    try:\n        # Try installing pre-built wheel first (faster)\n        !pip install -q flash-attn --no-build-isolation 2>/dev/null || \\\n         pip install -q flash-attn --no-build-isolation --no-cache-dir\n        print(\"✓ flash-attn installed successfully!\")\n    except:\n        print(\"⚠ Warning: flash-attn installation failed. Training will use standard attention.\")\n    \n    # Install kernel optimizations (Liger Kernel + Cut Cross-Entropy + 8-bit Adam)\n    print(\"\\nInstalling kernel optimizations...\")\n    \n    # Liger Kernel (~20% speedup, ~60% memory reduction)\n    !pip install -q liger-kernel\n    try:\n        import liger_kernel\n        print(\"✓ liger-kernel installed (~20% speedup, ~60% memory reduction)\")\n    except ImportError:\n        print(\"⚠ liger-kernel not available\")\n    \n    # bitsandbytes for 8-bit Adam optimizer (~4x memory reduction)\n    !pip install -q bitsandbytes\n    try:\n        import bitsandbytes\n        print(\"✓ bitsandbytes installed (8-bit Adam, ~4x optimizer memory reduction)\")\n    except ImportError:\n        print(\"⚠ bitsandbytes not available - using standard AdamW\")\n    \n    # Cut Cross-Entropy (may need specific torch version)\n    !pip install -q cut-cross-entropy\n    try:\n        import cut_cross_entropy\n        print(\"✓ cut-cross-entropy installed (~95% memory reduction on loss)\")\n    except ImportError:\n        print(\"⚠ cut-cross-entropy not available - trying alternative install...\")\n        !pip install -q git+https://github.com/apple/ml-cross-entropy.git\n        try:\n            import cut_cross_entropy\n            print(\"✓ cut-cross-entropy installed from source\")\n        except ImportError:\n            print(\"⚠ cut-cross-entropy could not be installed. Training will work without it.\")\n    \n    PROJECT_ROOT = REPO_DIR\n    print(\"\\n\" + \"=\"*50)\n    print(\"Installation complete!\")\n    print(\"=\"*50)\nelse:\n    # Local development - assume we're in the repo\n    PROJECT_ROOT = os.path.dirname(os.getcwd()) if 'notebooks' in os.getcwd() else os.getcwd()\n    \nprint(f\"\\nProject root: {PROJECT_ROOT}\")\nos.chdir(PROJECT_ROOT)\nsys.path.insert(0, os.path.join(PROJECT_ROOT, 'scripts'))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#@title ### 0.3 Set Up Persistent Storage (Google Drive)\n#@markdown Link checkpoints and data directories to Google Drive for persistence across sessions.\n\n#@markdown ---\nUSE_DRIVE_STORAGE = True  #@param {type:\"boolean\"}\n\nimport os\n\nif IN_COLAB and USE_DRIVE_STORAGE and DRIVE_BASE:\n    print(\"Setting up persistent storage on Google Drive...\")\n    \n    # Create ALL necessary directories on Drive FIRST (including subdirs)\n    drive_subdirs = [\n        'checkpoints',\n        'data',\n        'data/raw',        # Raw downloaded data\n        'data/processed',  # Cleaned data\n        'data/packed',     # Tokenized/packed data\n        'data/sft',        # SFT data\n        'data/dpo',        # DPO data\n        'logs',\n        'evals'\n    ]\n    \n    for subdir in drive_subdirs:\n        drive_path = os.path.join(DRIVE_BASE, subdir)\n        os.makedirs(drive_path, exist_ok=True)\n    \n    print(f\"  Created directory structure on Google Drive\")\n    \n    # Create symlinks for top-level directories only\n    local_dirs = ['checkpoints', 'data', 'logs', 'evals']\n    \n    for dir_name in local_dirs:\n        local_path = os.path.join(PROJECT_ROOT, dir_name)\n        drive_path = os.path.join(DRIVE_BASE, dir_name)\n        \n        # Remove local dir if it exists (but not if it's already a symlink)\n        if os.path.exists(local_path) and not os.path.islink(local_path):\n            # Move existing contents to drive\n            if os.listdir(local_path):\n                print(f\"  Moving existing {dir_name} to Drive...\")\n                !cp -r {local_path}/* {drive_path}/ 2>/dev/null || true\n            !rm -rf {local_path}\n        elif os.path.islink(local_path):\n            # Remove old symlink\n            os.unlink(local_path)\n        \n        # Create symlink\n        os.symlink(drive_path, local_path)\n        print(f\"  {dir_name} -> {drive_path}\")\n    \n    print(\"\\nPersistent storage configured!\")\n    print(\"Your checkpoints and data will survive Colab disconnections.\")\nelse:\n    print(\"Using local storage (not persistent in Colab)\")\n    # Create local directories\n    for dir_name in ['checkpoints', 'data', 'data/raw', 'data/processed', 'data/packed', 'logs', 'evals']:\n        os.makedirs(os.path.join(PROJECT_ROOT, dir_name), exist_ok=True)\n\n# Store paths for later use (always set these)\nDRIVE_DATA_RAW = os.path.join(DRIVE_BASE, \"data/raw\") if DRIVE_BASE else \"data/raw\"\nDRIVE_DATA_PROCESSED = os.path.join(DRIVE_BASE, \"data/processed\") if DRIVE_BASE else \"data/processed\"\n\n# Default cleaning paths (will be overridden by cell 0.3.1 if using local SSD)\nCLEANING_INPUT_DIR = \"data/raw\"\nCLEANING_OUTPUT_DIR = \"data/processed\"\n\nprint(f\"\\nData paths:\")\nprint(f\"  Raw data: {DRIVE_DATA_RAW}\")\nprint(f\"  Processed data: {DRIVE_DATA_PROCESSED}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#@title ### 0.3.1 Copy Data to Local SSD (Faster I/O) [Recommended]\n#@markdown **Copies data from Google Drive to local NVMe SSD for 5-10x faster I/O.**\n#@markdown\n#@markdown The local SSD in Colab is much faster than Google Drive for random I/O.\n#@markdown This significantly speeds up data cleaning and training.\n#@markdown\n#@markdown **When to use:**\n#@markdown - Before data cleaning (copy raw data)\n#@markdown - Before training (copy packed data)\n#@markdown - Results are automatically backed up to Drive when done\n\n#@markdown ---\nUSE_LOCAL_SSD = True  #@param {type:\"boolean\"}\n#@markdown *Enable local SSD for faster I/O during processing*\nCOPY_THREADS = 8  #@param {type:\"integer\"}\n#@markdown *Threads for parallel copy (8-16 recommended)*\n\nimport os\nimport shutil\nimport time\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom tqdm import tqdm\n\n# Try to import pyfastcopy for 30-50% faster per-file copy\ntry:\n    import pyfastcopy  # Patches shutil.copy2 to use sendfile syscall\n    FAST_COPY_AVAILABLE = True\nexcept ImportError:\n    FAST_COPY_AVAILABLE = False\n\n# Local SSD paths (fast storage, not persistent)\nLOCAL_DATA = \"/content/local_data\"\nLOCAL_RAW = f\"{LOCAL_DATA}/raw\"\nLOCAL_PROCESSED = f\"{LOCAL_DATA}/processed\"\nLOCAL_PACKED = f\"{LOCAL_DATA}/packed\"\nLOCAL_CACHE = f\"{LOCAL_DATA}/.cache\"\nLOCAL_CHECKPOINTS = \"/content/local_checkpoints\"\n\n# Drive paths (persistent)\nDRIVE_RAW = f\"{DRIVE_BASE}/data/raw\" if DRIVE_BASE else \"data/raw\"\nDRIVE_PROCESSED = f\"{DRIVE_BASE}/data/processed\" if DRIVE_BASE else \"data/processed\"\nDRIVE_PACKED = f\"{DRIVE_BASE}/data/packed\" if DRIVE_BASE else \"data/packed\"\nDRIVE_CHECKPOINTS = f\"{DRIVE_BASE}/checkpoints\" if DRIVE_BASE else \"checkpoints\"\n\ndef parallel_copy(src_dir, dst_dir, pattern=\"*\", max_workers=8, desc=\"Copying\"):\n    \"\"\"Copy files in parallel with progress bar.\"\"\"\n    import glob\n    \n    os.makedirs(dst_dir, exist_ok=True)\n    \n    # Find files to copy\n    if pattern == \"*\":\n        files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n    else:\n        files = [os.path.basename(f) for f in glob.glob(os.path.join(src_dir, pattern))]\n    \n    # Filter out already copied files\n    to_copy = []\n    total_size = 0\n    for f in files:\n        src = os.path.join(src_dir, f)\n        dst = os.path.join(dst_dir, f)\n        if not os.path.exists(dst) or os.path.getsize(src) != os.path.getsize(dst):\n            size = os.path.getsize(src)\n            to_copy.append((src, dst, f, size))\n            total_size += size\n    \n    if not to_copy:\n        print(f\"  All files already copied\")\n        return 0\n    \n    print(f\"  Copying {len(to_copy)} files ({total_size / (1024**3):.2f} GB)\")\n    if FAST_COPY_AVAILABLE:\n        print(f\"  Using: pyfastcopy + {max_workers} threads (fastest)\")\n    else:\n        print(f\"  Using: {max_workers} threads (install pyfastcopy for 30-50% faster)\")\n    \n    def copy_file(args):\n        src, dst, name, size = args\n        shutil.copy2(src, dst)\n        return name, size\n    \n    copied = 0\n    start_time = time.time()\n    \n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = {executor.submit(copy_file, args): args for args in to_copy}\n        with tqdm(total=total_size, unit='B', unit_scale=True, desc=f\"  {desc}\") as pbar:\n            for future in as_completed(futures):\n                name, size = future.result()\n                copied += 1\n                pbar.update(size)\n    \n    elapsed = time.time() - start_time\n    speed = total_size / (1024**2) / elapsed if elapsed > 0 else 0\n    print(f\"  Copied {copied} files in {elapsed:.1f}s ({speed:.0f} MB/s)\")\n    \n    return copied\n\nif IN_COLAB and USE_LOCAL_SSD:\n    print(\"Setting up local SSD for faster I/O...\")\n    print(\"=\" * 50)\n    \n    # Create local directories\n    for d in [LOCAL_DATA, LOCAL_RAW, LOCAL_PROCESSED, LOCAL_PACKED, LOCAL_CACHE, LOCAL_CHECKPOINTS]:\n        os.makedirs(d, exist_ok=True)\n    \n    # Check for existing raw data on Drive\n    if os.path.exists(DRIVE_RAW):\n        raw_files = [f for f in os.listdir(DRIVE_RAW) if f.endswith('.parquet')]\n        if raw_files:\n            print(f\"\\nFound {len(raw_files)} raw data files on Drive\")\n            parallel_copy(DRIVE_RAW, LOCAL_RAW, \"*.parquet\", COPY_THREADS, \"Raw data\")\n    \n    # Check for existing packed data on Drive\n    if os.path.exists(DRIVE_PACKED):\n        packed_files = list(os.listdir(DRIVE_PACKED))\n        if packed_files:\n            print(f\"\\nFound packed data on Drive\")\n            parallel_copy(DRIVE_PACKED, LOCAL_PACKED, \"*\", COPY_THREADS, \"Packed data\")\n    \n    # Store paths for use in other cells\n    CLEANING_INPUT_DIR = LOCAL_RAW\n    CLEANING_OUTPUT_DIR = LOCAL_PROCESSED\n    TRAINING_DATA_DIR = LOCAL_PACKED\n    TRAINING_CHECKPOINT_DIR = LOCAL_CHECKPOINTS\n    \n    # Check local disk space\n    import subprocess\n    result = subprocess.run(['df', '-h', '/content'], capture_output=True, text=True)\n    print(f\"\\nLocal SSD status:\")\n    print(result.stdout.split('\\n')[1])\n    \n    print(f\"\\nLocal SSD paths configured:\")\n    print(f\"  Raw data:    {LOCAL_RAW}\")\n    print(f\"  Processed:   {LOCAL_PROCESSED}\")\n    print(f\"  Packed:      {LOCAL_PACKED}\")\n    print(f\"  Checkpoints: {LOCAL_CHECKPOINTS}\")\n    print(\"=\" * 50)\nelse:\n    CLEANING_INPUT_DIR = \"data/raw\"\n    CLEANING_OUTPUT_DIR = \"data/processed\"\n    TRAINING_DATA_DIR = \"data/packed\"\n    TRAINING_CHECKPOINT_DIR = \"checkpoints\"\n    print(\"Using Google Drive paths (local SSD disabled)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Alternative: Install from pip (if repo is published)\n\nIf the package is published to PyPI or you prefer pip installation:\n\n```python\n# From PyPI (when published)\n!pip install llm-training-pipeline\n\n# From GitHub directly\n!pip install git+https://github.com/rmarnold/llm-training-pipeline.git\n\n# With FP8 support (H100 only)\n!pip install \"llm-training-pipeline[fp8]\"\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ### 0.4 Check GPU Availability\n#@markdown Verify GPU is available and check for FP8 support.\n\nimport torch\n\nprint(\"=\" * 50)\nprint(\"GPU INFORMATION\")\nprint(\"=\" * 50)\n\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n    print(f\"GPU: {gpu_name}\")\n    print(f\"Memory: {gpu_memory:.1f} GB\")\n    \n    # Check for H100/FP8 support\n    capability = torch.cuda.get_device_capability()\n    print(f\"Compute Capability: {capability[0]}.{capability[1]}\")\n    \n    if capability[0] >= 9:\n        print(\"FP8 Support: AVAILABLE (H100)\")\n        RECOMMENDED_PRECISION = \"fp8\"\n    elif capability[0] >= 8:\n        print(\"FP8 Support: Not available (use BF16)\")\n        RECOMMENDED_PRECISION = \"bf16\"\n    else:\n        print(\"FP8 Support: Not available\")\n        RECOMMENDED_PRECISION = \"fp16\"\n    \n    # Memory recommendation\n    if gpu_memory >= 80:\n        print(f\"\\nRecommendation: Full 7B training supported\")\n    elif gpu_memory >= 40:\n        print(f\"\\nRecommendation: Use gradient checkpointing, smaller batch size\")\n    else:\n        print(f\"\\nWarning: GPU memory may be insufficient for 7B model\")\n        print(\"Consider using LoRA or a smaller model\")\nelse:\n    print(\"WARNING: No GPU detected!\")\n    print(\"Training will be extremely slow on CPU.\")\n    RECOMMENDED_PRECISION = \"fp32\"\n\nprint(\"=\" * 50)"
  },
  {
   "cell_type": "code",
   "source": "#@title ### 0.5 Start GPU Keepalive (Prevents Idle Timeout) [DISABLED]\n#@markdown **Note:** GPU keepalive is currently disabled. Uncomment the code below to enable if needed.\n#@markdown \n#@markdown This starts a background process that periodically pings the GPU to prevent Colab from timing out during long CPU-bound operations (like data cleaning).\n\n# GPU Keepalive is DISABLED - uncomment below to enable\n# import subprocess\n# import os\n# \n# if IN_COLAB:\n#     # Kill any existing keepalive process\n#     !pkill -f gpu_keepalive.py 2>/dev/null || true\n#     \n#     # Start GPU keepalive in background\n#     keepalive_script = os.path.join(PROJECT_ROOT, 'scripts', 'gpu_keepalive.py')\n#     \n#     if os.path.exists(keepalive_script):\n#         process = subprocess.Popen(\n#             ['python', keepalive_script],\n#             stdout=subprocess.DEVNULL,\n#             stderr=subprocess.DEVNULL,\n#             start_new_session=True\n#         )\n#         print(f\"GPU Keepalive started (PID: {process.pid})\")\n#         print(\"  - Checks GPU every 60 seconds\")\n#         print(\"  - Sends keepalive spike if idle for 5+ minutes\")\n#         print(\"  - Prevents Colab idle timeout during CPU-bound tasks\")\n#         print(f\"\\nTo stop: !pkill -f gpu_keepalive.py\")\n#     else:\n#         print(\"Warning: gpu_keepalive.py not found. Run 'git pull' to get latest code.\")\n# else:\n#     print(\"GPU keepalive not needed outside of Colab\")\n\nprint(\"GPU Keepalive: DISABLED\")\nprint(\"To enable, uncomment the code in this cell.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ### 0.5 Training Configuration {run: \"auto\"}\n#@markdown Adjust these settings based on your GPU and requirements.\n\n#@markdown ---\n#@markdown **Model Size:**\nmodel_size = \"7b\"  #@param [\"125m\", \"350m\", \"1b\", \"3b\", \"7b\"]\n#@markdown *Available sizes: 125M (~124M params), 350M, 1B, 3B, 7B*\ncontext_length = 4096  #@param {type:\"integer\"}\n#@markdown *Max context length (tokens). Larger = more memory.*\n\n#@markdown ---\n#@markdown **General Settings:**\nuse_fp8 = \"auto\"  #@param [\"auto\", \"true\", \"false\"]\nseed = 42  #@param {type:\"integer\"}\nenable_oom_recovery = True  #@param {type:\"boolean\"}\n\n#@markdown ---\n#@markdown **Kernel Optimizations (Recommended):**\nuse_liger_kernel = True  #@param {type:\"boolean\"}\n#@markdown *Liger Kernel: ~20% speedup, ~60% memory reduction*\nuse_cce = True  #@param {type:\"boolean\"}\n#@markdown *Cut Cross-Entropy: ~95% memory reduction on loss computation*\n\n#@markdown ---\n#@markdown **Data Cleaning:**\npipeline_mode = \"native\"  #@param [\"native\", \"legacy\"]\n#@markdown *Pipeline modes:*\n#@markdown - **native**: Uses datatrove's optimized pipeline (3-5x faster, recommended)\n#@markdown - **legacy**: Uses multiprocessing Pool (fallback if native fails)\n\nuse_full_clean = False  #@param {type:\"boolean\"}\n#@markdown *Full clean uses plsfix (Rust) for Unicode/mojibake fixing. Slower but more thorough.*\n\nquality_filter_mode = \"default\"  #@param [\"default\", \"fast\", \"no-repetition\", \"no-fineweb\"]\n#@markdown *Quality filter modes:*\n#@markdown - **default**: All filters (GopherQuality + FineWeb + GopherRepetition)\n#@markdown - **fast**: Only GopherQuality (~3x faster, basic filtering)\n#@markdown - **no-repetition**: Skip n-gram analysis (~2x faster, may miss spam)\n#@markdown - **no-fineweb**: Skip line structure checks (~15% faster)\n\n#@markdown ---\n#@markdown **Pretraining:**\npretrain_max_steps = 100000  #@param {type:\"integer\"}\npretrain_save_steps = 1000  #@param {type:\"integer\"}\npretrain_eval_steps = 1000  #@param {type:\"integer\"}\n\n#@markdown ---\n#@markdown **SFT:**\nsft_max_steps = 5000  #@param {type:\"integer\"}\nsft_save_steps = 500  #@param {type:\"integer\"}\n\n#@markdown ---\n#@markdown **DPO:**\ndpo_max_steps = 2000  #@param {type:\"integer\"}\ndpo_save_steps = 200  #@param {type:\"integer\"}\n\n# Model size to batch size recommendations (A100 80GB)\nBATCH_SIZE_MAP = {\n    \"125m\": {\"batch_size\": 32, \"grad_accum\": 1},\n    \"350m\": {\"batch_size\": 16, \"grad_accum\": 2},\n    \"1b\": {\"batch_size\": 16, \"grad_accum\": 2},\n    \"3b\": {\"batch_size\": 8, \"grad_accum\": 4},\n    \"7b\": {\"batch_size\": 8, \"grad_accum\": 4},\n}\n\nbatch_rec = BATCH_SIZE_MAP.get(model_size, {\"batch_size\": 8, \"grad_accum\": 4})\n\n# Build config dict\nCONFIG = {\n    'model_size': model_size,\n    'context_length': context_length,\n    'use_fp8': None if use_fp8 == \"auto\" else (use_fp8 == \"true\"),\n    'seed': seed,\n    'enable_oom_recovery': enable_oom_recovery,\n    'use_liger_kernel': use_liger_kernel,\n    'use_cce': use_cce,\n    'pipeline_mode': pipeline_mode,\n    'use_full_clean': use_full_clean,\n    'quality_filter_mode': quality_filter_mode,\n    'pretrain_max_steps': pretrain_max_steps,\n    'pretrain_save_steps': pretrain_save_steps,\n    'pretrain_eval_steps': pretrain_eval_steps,\n    'sft_max_steps': sft_max_steps,\n    'sft_save_steps': sft_save_steps,\n    'dpo_max_steps': dpo_max_steps,\n    'dpo_save_steps': dpo_save_steps,\n    'batch_size': batch_rec['batch_size'],\n    'grad_accum': batch_rec['grad_accum'],\n}\n\n# Model size descriptions\nSIZE_INFO = {\n    \"125m\": \"~124M params - Fast training, good for testing\",\n    \"350m\": \"~350M params - Small but capable\",\n    \"1b\": \"~1B params - Good balance of speed and capability\",\n    \"3b\": \"~3B params - Strong performance, moderate memory\",\n    \"7b\": \"~7B params - Full capability, requires A100 80GB\",\n}\n\nprint(\"=\" * 60)\nprint(\"TRAINING CONFIGURATION\")\nprint(\"=\" * 60)\nprint(f\"\\nModel: {model_size.upper()} - {SIZE_INFO[model_size]}\")\nprint(f\"Context length: {context_length} tokens\")\nprint(f\"\\nRecommended batch settings:\")\nprint(f\"  batch_size: {batch_rec['batch_size']}\")\nprint(f\"  gradient_accumulation: {batch_rec['grad_accum']}\")\nprint(f\"  effective_batch: {batch_rec['batch_size'] * batch_rec['grad_accum']}\")\n\nif use_liger_kernel or use_cce:\n    print(\"\\nKernel Optimizations:\")\n    if use_liger_kernel:\n        print(\"  - Liger Kernel: Fused Triton kernels (~20% speedup)\")\n    if use_cce:\n        print(\"  - Cut Cross-Entropy: Memory-efficient loss (~95% reduction)\")\n\nprint(f\"\\nPipeline Mode: {'NATIVE DATATROVE' if pipeline_mode == 'native' else 'LEGACY'}\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pre-flight Validation\n",
    "\n",
    "Before starting training, validate that all prerequisites are in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pre-flight checks for a specific stage\n",
    "# Options: 'pretrain', 'sft', 'dpo', 'lora'\n",
    "\n",
    "STAGE_TO_CHECK = 'pretrain'  # Change this to check different stages\n",
    "\n",
    "!python scripts/preflight_check.py {STAGE_TO_CHECK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all pre-flight checks\n",
    "!python scripts/preflight_check.py --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 1: Data Preparation\n",
    "\n",
    "Download, clean, and prepare training data. Skip this section if data is already prepared."
   ]
  },
  {
   "cell_type": "code",
   "source": "#@title ### Step 1.1: Download raw data\n#@markdown Downloads pretraining data from configured sources (HuggingFace).\n#@markdown Data is saved to local SSD for speed, then backed up to Drive.\n\nimport os\n\n# Determine output directory\nif 'USE_LOCAL_SSD' in dir() and USE_LOCAL_SSD and IN_COLAB:\n    download_dir = LOCAL_RAW\n    backup_dir = DRIVE_RAW\n    print(f\"Downloading to local SSD: {download_dir}\")\n    print(f\"Backup will be saved to: {backup_dir}\")\nelse:\n    download_dir = \"data/raw\"\n    backup_dir = None\n    print(f\"Downloading to: {download_dir}\")\n\nprint(\"=\" * 50)\n\n# Download\n!python scripts/01_download_data.py --output-dir {download_dir}\n\n# Backup to Drive\nif backup_dir:\n    print(f\"\\nBacking up to Google Drive...\")\n    os.makedirs(backup_dir, exist_ok=True)\n    !cp -r {download_dir}/*.parquet {backup_dir}/ 2>/dev/null || true\n    print(\"Backup complete!\")\n\n# Check what was downloaded\nif os.path.exists(download_dir):\n    files = [f for f in os.listdir(download_dir) if f.endswith('.parquet')]\n    print(f\"\\nDownloaded {len(files)} files:\")\n    for f in files:\n        size_mb = os.path.getsize(f\"{download_dir}/{f}\") / (1024*1024)\n        print(f\"  - {f} ({size_mb:.1f} MB)\")\nelse:\n    print(\"\\nNo data downloaded. Check the script output above for errors.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ### Step 1.2: Clean and deduplicate data\n#@markdown Removes duplicates, filters low-quality content.\n#@markdown Uses local SSD for faster I/O, syncs to Google Drive after completion.\n\n#@markdown ---\n#@markdown **Auto-sync to Drive (for recovery):**\nAUTO_SYNC_TO_DRIVE = True  #@param {type:\"boolean\"}\n#@markdown *Automatically sync after cleaning for recovery if interrupted*\n\nimport os\n\n# Build cleaning command\nclean_cmd = \"python scripts/02_gpu_clean_deduplicate.py\"\n\n# Use local SSD paths if configured\nif 'USE_LOCAL_SSD' in dir() and USE_LOCAL_SSD and IN_COLAB:\n    input_dir = LOCAL_RAW\n    output_dir = LOCAL_PROCESSED\n    cache_dir = LOCAL_CACHE\n    backup_dir = DRIVE_PROCESSED\n    print(f\"Using LOCAL SSD for faster I/O (5-10x speedup)\")\n    print(f\"  Input:  {input_dir}\")\n    print(f\"  Output: {output_dir}\")\n    print(f\"  Cache:  {cache_dir}\")\n    clean_cmd += f\" --input {input_dir} --output {output_dir} --cache {cache_dir}\"\nelse:\n    input_dir = CLEANING_INPUT_DIR\n    output_dir = CLEANING_OUTPUT_DIR\n    backup_dir = None\n    print(f\"Using default paths\")\n    print(f\"  Input:  {input_dir}\")\n    print(f\"  Output: {output_dir}\")\n    if input_dir != \"data/raw\":\n        clean_cmd += f\" --input {input_dir} --output {output_dir}\"\n\n# Pipeline mode (native datatrove vs legacy multiprocessing)\npipeline_mode = CONFIG.get('pipeline_mode', 'native')\nif pipeline_mode == 'native':\n    clean_cmd += \" --native-pipeline\"\n\n# Quality filter mode\nfilter_mode = CONFIG.get('quality_filter_mode', 'default')\nif filter_mode == 'fast':\n    clean_cmd += \" --fast-quality --no-toxicity\"\nelif filter_mode == 'no-repetition':\n    clean_cmd += \" --no-repetition-filter\"\nelif filter_mode == 'no-fineweb':\n    clean_cmd += \" --no-fineweb-filter\"\n\nprint(f\"\\nPipeline mode: {'GPU (RAPIDS + NeMo)' if 'gpu' in clean_cmd else 'NATIVE DATATROVE' if pipeline_mode == 'native' else 'LEGACY'}\")\nprint(f\"Quality filters: {filter_mode}\")\nprint(f\"\\nCommand: {clean_cmd}\")\nprint(\"=\" * 50)\n\n!{clean_cmd}\n\n# Backup to Drive after cleaning\nif backup_dir and AUTO_SYNC_TO_DRIVE:\n    print(f\"\\nBacking up processed data to Google Drive...\")\n    os.makedirs(backup_dir, exist_ok=True)\n    !cp -r {output_dir}/* {backup_dir}/ 2>/dev/null || true\n    print(\"Backup complete!\")"
  },
  {
   "cell_type": "code",
   "source": "#@title ### Step 1.2.1: Verify/Manual Sync to Google Drive [Optional]\n#@markdown **Verify sync status or force manual sync if auto-sync was disabled.**\n#@markdown\n#@markdown With `AUTO_SYNC_TO_DRIVE=True` in Step 1.2, this cell is usually not needed.\n#@markdown Use this for:\n#@markdown - Verifying data is synced to Drive\n#@markdown - Manual sync if auto-sync was disabled\n#@markdown - Re-syncing after resuming from an interrupted session\n\n#@markdown ---\nFORCE_SYNC = False  #@param {type:\"boolean\"}\n#@markdown *Force sync even if files appear up-to-date*\nSYNC_THREADS = 10  #@param {type:\"integer\"}\n#@markdown *Threads for parallel sync (10-20 for many files, 2-4 for large files)*\n\nimport os\nimport json\nimport shutil\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom tqdm import tqdm\n\n# Try to import pyfastcopy for 30-50% faster per-file copy\ntry:\n    import pyfastcopy  # Patches shutil.copy2 to use sendfile syscall\n    FAST_COPY_AVAILABLE = True\nexcept ImportError:\n    FAST_COPY_AVAILABLE = False\n\ndef check_stage_status(output_dir: str) -> dict:\n    \"\"\"Check cleaning stage status from state file.\"\"\"\n    state_file = os.path.join(output_dir, \".stage_state.json\")\n    if os.path.exists(state_file):\n        with open(state_file) as f:\n            return json.load(f)\n    return {'completed_stages': [], 'last_stage': None}\n\ndef sync_files_parallel(src_dir: str, dst_dir: str, files: list, max_workers: int = 10):\n    \"\"\"Parallel file sync with progress bar.\"\"\"\n    if not files:\n        return 0\n\n    # Build list of files to sync with sizes\n    to_sync = []\n    total_size = 0\n    for f in files:\n        src = os.path.join(src_dir, f)\n        dst = os.path.join(dst_dir, f)\n        size = os.path.getsize(src)\n        to_sync.append((src, dst, f, size))\n        total_size += size\n\n    if FAST_COPY_AVAILABLE:\n        print(f\"  Using: pyfastcopy + {max_workers} threads\")\n    else:\n        print(f\"  Using: {max_workers} threads\")\n\n    def copy_file(args):\n        src, dst, name, size = args\n        shutil.copy2(src, dst)  # pyfastcopy patches this if available\n        return name, size\n\n    synced = 0\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = {executor.submit(copy_file, args): args for args in to_sync}\n        with tqdm(total=total_size, unit='B', unit_scale=True, desc=\"  Syncing\") as pbar:\n            for future in as_completed(futures):\n                name, size = future.result()\n                synced += 1\n                pbar.update(size)\n\n    return synced\n\n# Check if using local SSD\ntry:\n    using_local_ssd = CLEANING_OUTPUT_DIR.startswith(\"/content/data_local\")\nexcept NameError:\n    using_local_ssd = False\n\nprint(\"=\" * 50)\nprint(\"CLEANING STAGE STATUS\")\nprint(\"=\" * 50)\n\n# Check local status\nlocal_output = CLEANING_OUTPUT_DIR if 'CLEANING_OUTPUT_DIR' in dir() else \"data/processed\"\nlocal_status = check_stage_status(local_output)\n\nprint(f\"\\nLocal ({local_output}):\")\nif local_status['completed_stages']:\n    for stage in ['text_clean', 'quality_filter', 'toxicity_filter', 'dedup', 'final']:\n        status = \"COMPLETE\" if stage in local_status['completed_stages'] else \"pending\"\n        print(f\"  {stage}: {status}\")\nelse:\n    print(\"  No stage state found (cleaning may not have started)\")\n\n# Check Drive status\nif IN_COLAB and DRIVE_BASE:\n    drive_processed = os.path.join(DRIVE_BASE, \"data/processed\")\n    drive_status = check_stage_status(drive_processed)\n\n    print(f\"\\nGoogle Drive ({drive_processed}):\")\n    if drive_status['completed_stages']:\n        for stage in ['text_clean', 'quality_filter', 'toxicity_filter', 'dedup', 'final']:\n            status = \"COMPLETE\" if stage in drive_status['completed_stages'] else \"pending\"\n            print(f\"  {stage}: {status}\")\n    else:\n        print(\"  No stage state found\")\n\n    # Compare file counts\n    local_files = set(f for f in os.listdir(local_output) if f.endswith('.parquet')) if os.path.exists(local_output) else set()\n    drive_files = set(f for f in os.listdir(drive_processed) if f.endswith('.parquet')) if os.path.exists(drive_processed) else set()\n\n    print(f\"\\nFile comparison:\")\n    print(f\"  Local files:  {len(local_files)}\")\n    print(f\"  Drive files:  {len(drive_files)}\")\n\n    if local_files == drive_files:\n        print(\"  Status: IN SYNC\")\n    else:\n        missing_on_drive = local_files - drive_files\n        if missing_on_drive:\n            print(f\"  Missing on Drive: {len(missing_on_drive)} files\")\n            if FORCE_SYNC:\n                print(\"\\nSyncing missing files to Google Drive...\")\n                os.makedirs(drive_processed, exist_ok=True)\n                synced = sync_files_parallel(\n                    local_output, drive_processed,\n                    list(missing_on_drive),\n                    max_workers=SYNC_THREADS\n                )\n                print(f\"  Synced {synced} files to Drive!\")\n            else:\n                print(\"  Set FORCE_SYNC=True to sync missing files\")\n\nprint(\"=\" * 50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ### Step 1.3: Tokenize and pack sequences\n#@markdown Creates packed sequences for efficient training.\n#@markdown Uses local SSD for faster I/O, backs up to Drive when done.\n\nimport os\n\n# Determine paths\nif 'USE_LOCAL_SSD' in dir() and USE_LOCAL_SSD and IN_COLAB:\n    input_dir = LOCAL_PROCESSED\n    output_dir = LOCAL_PACKED\n    backup_dir = DRIVE_PACKED\n    print(f\"Using LOCAL SSD for faster I/O\")\n    print(f\"  Input:  {input_dir}\")\n    print(f\"  Output: {output_dir}\")\nelse:\n    input_dir = \"data/processed\"\n    output_dir = \"data/packed\"\n    backup_dir = None\n    print(f\"Using default paths\")\n\nprint(\"=\" * 50)\n\n!python scripts/03_tokenize_and_pack.py --input-dir {input_dir} --output-dir {output_dir}\n\n# Backup to Drive\nif backup_dir:\n    print(f\"\\nBacking up packed data to Google Drive...\")\n    os.makedirs(backup_dir, exist_ok=True)\n    !cp -r {output_dir}/* {backup_dir}/ 2>/dev/null || true\n    print(\"Backup complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 1.4: Initialize model with selected size\n# Creates the initial model checkpoint based on CONFIG['model_size']\n\nmodel_size = CONFIG.get('model_size', '7b')\ncontext_length = CONFIG.get('context_length', 4096)\n\nprint(f\"Initializing {model_size.upper()} model with {context_length} context length...\")\n\ninit_cmd = f\"python scripts/04_init_model.py --size {model_size} --context-length {context_length}\"\nprint(f\"Command: {init_cmd}\\n\")\n\n!{init_cmd}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data preparation\n",
    "import os\n",
    "\n",
    "paths_to_check = [\n",
    "    ('Tokenizer', 'configs/tokenizer'),\n",
    "    ('Initial model', 'checkpoints/init'),\n",
    "    ('Training data', 'data/packed/train'),\n",
    "    ('Validation data', 'data/packed/val'),\n",
    "]\n",
    "\n",
    "print(\"Data preparation status:\")\n",
    "print(\"=\" * 50)\n",
    "all_ready = True\n",
    "for name, path in paths_to_check:\n",
    "    exists = os.path.exists(path)\n",
    "    status = \"OK\" if exists else \"MISSING\"\n",
    "    print(f\"  {name}: {status}\")\n",
    "    all_ready = all_ready and exists\n",
    "\n",
    "print(\"=\" * 50)\n",
    "if all_ready:\n",
    "    print(\"All data preparation complete! Ready for pretraining.\")\n",
    "else:\n",
    "    print(\"Some data is missing. Run the preparation steps above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 2: Pretraining\n",
    "\n",
    "Train the base model on large text corpora. This is the longest stage.\n",
    "\n",
    "**Estimated time:** 25-50 hours depending on GPU (H100 FP8 fastest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Build pretraining command with model-size-appropriate batch settings\npretrain_cmd = \"python scripts/05_pretrain.py\"\n\nif CONFIG['use_fp8'] is True:\n    pretrain_cmd += \" --fp8\"\nelif CONFIG['use_fp8'] is False:\n    pretrain_cmd += \" --no-fp8\"\n\npretrain_cmd += f\" --max_steps {CONFIG['pretrain_max_steps']}\"\npretrain_cmd += f\" --save_steps {CONFIG['pretrain_save_steps']}\"\npretrain_cmd += f\" --eval_steps {CONFIG['pretrain_eval_steps']}\"\npretrain_cmd += f\" --seed {CONFIG['seed']}\"\n\nif CONFIG['enable_oom_recovery']:\n    pretrain_cmd += \" --enable-oom-recovery\"\n\n# Kernel optimizations (enabled by default)\nif CONFIG.get('use_liger_kernel', True):\n    pretrain_cmd += \" --use-liger-kernel\"\nelse:\n    pretrain_cmd += \" --no-liger-kernel\"\n\nif CONFIG.get('use_cce', True):\n    pretrain_cmd += \" --use-cce\"\nelse:\n    pretrain_cmd += \" --no-cce\"\n\nprint(\"=\" * 60)\nprint(\"PRETRAINING CONFIGURATION\")\nprint(\"=\" * 60)\nprint(f\"Model size: {CONFIG.get('model_size', '7b').upper()}\")\nprint(f\"Batch size: {CONFIG['batch_size']} (recommended for this model size)\")\nprint(f\"Gradient accumulation: {CONFIG['grad_accum']}\")\nprint(f\"Effective batch: {CONFIG['batch_size'] * CONFIG['grad_accum']}\")\nprint(f\"Max steps: {CONFIG['pretrain_max_steps']}\")\nprint(f\"\\nCommand: {pretrain_cmd}\")\n\nif CONFIG.get('use_liger_kernel') or CONFIG.get('use_cce'):\n    print(\"\\nKernel optimizations enabled for faster training!\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ### Start pretraining\n#@markdown Runs pretraining with local SSD for faster data loading.\n#@markdown Checkpoints are saved locally and backed up to Drive after training.\n\nimport os\n\n# Build command with local SSD paths if configured\npretrain_cmd_local = pretrain_cmd\n\nif 'USE_LOCAL_SSD' in dir() and USE_LOCAL_SSD and IN_COLAB:\n    data_path = LOCAL_PACKED\n    checkpoint_path = f\"{LOCAL_CHECKPOINTS}/pretrain\"\n    backup_checkpoint_dir = f\"{DRIVE_CHECKPOINTS}/pretrain\"\n    \n    pretrain_cmd_local += f\" --train_data_path {data_path}\"\n    pretrain_cmd_local += f\" --output_dir {checkpoint_path}\"\n    \n    print(f\"Using LOCAL SSD for faster I/O:\")\n    print(f\"  Data: {data_path}\")\n    print(f\"  Checkpoints: {checkpoint_path}\")\nelse:\n    backup_checkpoint_dir = None\n    print(\"Using default paths\")\n\nprint(f\"\\nCommand: {pretrain_cmd_local}\")\nprint(\"=\" * 50)\n\n# Run training\n!{pretrain_cmd_local}\n\n# Backup checkpoints to Drive after training\nif backup_checkpoint_dir:\n    print(f\"\\nBacking up checkpoints to Google Drive...\")\n    os.makedirs(backup_checkpoint_dir, exist_ok=True)\n    !cp -r {checkpoint_path}/* {backup_checkpoint_dir}/ 2>/dev/null || true\n    # Also backup final checkpoint\n    if os.path.exists(f\"{LOCAL_CHECKPOINTS}/pretrain_final\"):\n        !cp -r {LOCAL_CHECKPOINTS}/pretrain_final {DRIVE_CHECKPOINTS}/ 2>/dev/null || true\n    print(\"Checkpoint backup complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume pretraining from checkpoint (if interrupted)\n",
    "# Uncomment and modify the checkpoint path as needed\n",
    "\n",
    "# CHECKPOINT_PATH = \"checkpoints/pretrain/checkpoint-5000\"\n",
    "# !python scripts/05_pretrain.py --resume_from_checkpoint {CHECKPOINT_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 3: Supervised Fine-Tuning (SFT)\n",
    "\n",
    "Fine-tune on instruction-response pairs to create a helpful assistant.\n",
    "\n",
    "**Estimated time:** 2-5 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare SFT data (if not already done)\n",
    "!python scripts/06_prepare_sft_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify pretrained checkpoint exists\n",
    "import os\n",
    "\n",
    "if os.path.exists('checkpoints/pretrain_final'):\n",
    "    print(\"Pretrained checkpoint found. Ready for SFT.\")\n",
    "else:\n",
    "    print(\"ERROR: Pretrained checkpoint not found!\")\n",
    "    print(\"Complete pretraining before starting SFT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SFT command\n",
    "sft_cmd = \"python scripts/07_sft.py\"\n",
    "\n",
    "if CONFIG['use_fp8'] is True:\n",
    "    sft_cmd += \" --fp8\"\n",
    "elif CONFIG['use_fp8'] is False:\n",
    "    sft_cmd += \" --no-fp8\"\n",
    "\n",
    "sft_cmd += f\" --max_steps {CONFIG['sft_max_steps']}\"\n",
    "sft_cmd += f\" --save_steps {CONFIG['sft_save_steps']}\"\n",
    "sft_cmd += f\" --seed {CONFIG['seed']}\"\n",
    "\n",
    "if CONFIG['enable_oom_recovery']:\n",
    "    sft_cmd += \" --enable-oom-recovery\"\n",
    "\n",
    "print(\"SFT command:\")\n",
    "print(sft_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start SFT training\n",
    "!{sft_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 4: Direct Preference Optimization (DPO)\n",
    "\n",
    "Align the model with human preferences using chosen/rejected response pairs.\n",
    "\n",
    "**Estimated time:** 1-3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DPO data\n",
    "!python scripts/08_prepare_dpo_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify SFT checkpoint exists\n",
    "import os\n",
    "\n",
    "if os.path.exists('checkpoints/sft_final'):\n",
    "    print(\"SFT checkpoint found. Ready for DPO.\")\n",
    "else:\n",
    "    print(\"ERROR: SFT checkpoint not found!\")\n",
    "    print(\"Complete SFT before starting DPO.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DPO command\n",
    "dpo_cmd = \"python scripts/09_dpo.py\"\n",
    "\n",
    "if CONFIG['use_fp8'] is True:\n",
    "    dpo_cmd += \" --fp8\"\n",
    "elif CONFIG['use_fp8'] is False:\n",
    "    dpo_cmd += \" --no-fp8\"\n",
    "\n",
    "dpo_cmd += f\" --max_steps {CONFIG['dpo_max_steps']}\"\n",
    "dpo_cmd += f\" --save_steps {CONFIG['dpo_save_steps']}\"\n",
    "dpo_cmd += f\" --seed {CONFIG['seed']}\"\n",
    "\n",
    "if CONFIG['enable_oom_recovery']:\n",
    "    dpo_cmd += \" --enable-oom-recovery\"\n",
    "\n",
    "print(\"DPO command:\")\n",
    "print(dpo_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start DPO training\n",
    "!{dpo_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Stage 5: LoRA Fine-Tuning (Optional)\n",
    "\n",
    "Domain-specific adaptation using LoRA for efficient fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA fine-tuning (optional)\n",
    "# Uncomment to run LoRA training\n",
    "\n",
    "# !python scripts/10_lora_finetune.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation\n",
    "\n",
    "Evaluate the trained model on various benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full evaluation suite\n",
    "CHECKPOINT_TO_EVAL = \"checkpoints/dpo_final\"  # Change as needed\n",
    "\n",
    "!python scripts/11_evaluate.py {CHECKPOINT_TO_EVAL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check promotion gates\n",
    "# Verify model meets quality thresholds\n",
    "\n",
    "STAGE_TO_CHECK = \"dpo\"  # Options: pretrain, sft, dpo\n",
    "\n",
    "!python scripts/12_check_gates.py {STAGE_TO_CHECK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Monitoring & Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor GPU utilization\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all checkpoints\n",
    "!bash scripts/checkpoint_manager.sh list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show disk usage\n",
    "!bash scripts/checkpoint_manager.sh disk-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup old checkpoints (keep latest 3)\n",
    "# Uncomment to run\n",
    "\n",
    "# !bash scripts/checkpoint_manager.sh cleanup pretrain 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Inference\n",
    "\n",
    "Test the trained model with interactive generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model for inference\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "MODEL_PATH = \"checkpoints/dpo_final\"  # Change to your checkpoint\n",
    "\n",
    "print(f\"Loading model from {MODEL_PATH}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"configs/tokenizer\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "def generate(prompt, max_new_tokens=256, temperature=0.7):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Test generation\n",
    "prompt = \"Explain machine learning in simple terms:\"\n",
    "print(f\"Prompt: {prompt}\\n\")\n",
    "print(f\"Response: {generate(prompt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive generation cell\n",
    "# Modify the prompt and run to test different inputs\n",
    "\n",
    "PROMPT = \"Write a Python function to calculate fibonacci numbers:\"\n",
    "\n",
    "print(f\"Prompt: {PROMPT}\\n\")\n",
    "print(\"=\" * 50)\n",
    "print(generate(PROMPT, max_new_tokens=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Summary\n",
    "\n",
    "After completing all stages, review the training summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training report\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING PIPELINE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stages = [\n",
    "    ('Pretrain', 'checkpoints/pretrain_final'),\n",
    "    ('SFT', 'checkpoints/sft_final'),\n",
    "    ('DPO', 'checkpoints/dpo_final'),\n",
    "    ('LoRA', 'checkpoints/lora_final'),\n",
    "]\n",
    "\n",
    "print(\"\\nCheckpoint Status:\")\n",
    "for name, path in stages:\n",
    "    if os.path.exists(path):\n",
    "        # Get checkpoint size\n",
    "        size = sum(os.path.getsize(os.path.join(path, f)) for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)))\n",
    "        size_gb = size / (1024**3)\n",
    "        print(f\"  {name}: COMPLETE ({size_gb:.2f} GB)\")\n",
    "    else:\n",
    "        print(f\"  {name}: Not completed\")\n",
    "\n",
    "print(\"\\nEvaluation Results:\")\n",
    "eval_path = \"evals/\"\n",
    "if os.path.exists(eval_path):\n",
    "    for f in os.listdir(eval_path):\n",
    "        if f.endswith('.json'):\n",
    "            with open(os.path.join(eval_path, f)) as file:\n",
    "                results = json.load(file)\n",
    "                print(f\"  {f}: {results}\")\n",
    "else:\n",
    "    print(\"  No evaluation results found. Run evaluation first.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}