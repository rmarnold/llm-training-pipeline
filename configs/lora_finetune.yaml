run_name: "llm-7b-lora-coding"

model:
  base_checkpoint: "checkpoints/dpo_final"

lora:
  r: 64  # LoRA rank
  lora_alpha: 128
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
  lora_dropout: 0.05
  bias: "none"
  task_type: "CAUSAL_LM"

data:
  domain_data: "data/domain/coding"  # Domain-specific dataset
  general_data: "data/sft/train"  # Mix in general data
  domain_weight: 0.7
  general_weight: 0.3

training:
  num_train_epochs: 5
  learning_rate: 1.0e-4

  per_device_train_batch_size: 4
  gradient_accumulation_steps: 8

  bf16: true
  max_seq_length: 2048

eval:
  domain_benchmarks: ["HumanEval", "MBPP"]
  general_benchmarks: ["MMLU", "TruthfulQA"]
  promotion_threshold:
    domain: 0.7  # Must achieve >70% on domain evals
    general: 0.0  # No regression on general evals
